{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5537e7ba-6f2a-4778-8f06-c29d9af0de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Ok\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Imports Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83110995-66cb-471c-924c-bc7eb1568882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df = pd.read_csv(\"magic04.data\", names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962be496-49d8-460a-9aa8-e6ba62153ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude useless data\n",
    "#df = df.drop(columns=[ \"fSize\", \"fConc\", \"fConc1\", \"fDist\", \"fM3Trans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b122faac-d4ed-4754-aaad-cd1aa5a2aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_features(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(dataframe[column]):\n",
    "            voc = dataframe[column].unique()\n",
    "            voc.sort()\n",
    "            mapping = {val: i for i, val in enumerate(voc)}\n",
    "            dataframe[column] = dataframe[column].map(mapping)\n",
    "                \n",
    "\n",
    "init_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970481b7-5c3f-4800-9d4d-4753bc252657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "def plotfeatclass(dataframe, classname):\n",
    "    for cl in classname:\n",
    "        for label in df.columns[:-1]:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "            ax1.hist(df[df[cl] == 1][label], color='blue', label='gamma')\n",
    "            ax2.hist(df[df[cl] == 0][label], color='red', label='hadron')\n",
    "            plt.title(label)\n",
    "            plt.show()\n",
    "\n",
    "#plotfeatclass(df, [\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984de7c8-6cf1-4c13-95ec-dc946ef72b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.062415</td>\n",
       "      <td>0.208043</td>\n",
       "      <td>0.430390</td>\n",
       "      <td>0.293229</td>\n",
       "      <td>0.470032</td>\n",
       "      <td>0.620576</td>\n",
       "      <td>0.512493</td>\n",
       "      <td>0.445467</td>\n",
       "      <td>0.163066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082815</td>\n",
       "      <td>0.045727</td>\n",
       "      <td>0.170668</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.468649</td>\n",
       "      <td>0.623756</td>\n",
       "      <td>0.507944</td>\n",
       "      <td>0.070677</td>\n",
       "      <td>0.412679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478241</td>\n",
       "      <td>0.530579</td>\n",
       "      <td>0.626818</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>0.556215</td>\n",
       "      <td>0.468201</td>\n",
       "      <td>0.416540</td>\n",
       "      <td>0.855111</td>\n",
       "      <td>0.516926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059212</td>\n",
       "      <td>0.037338</td>\n",
       "      <td>0.117445</td>\n",
       "      <td>0.683714</td>\n",
       "      <td>0.580679</td>\n",
       "      <td>0.469558</td>\n",
       "      <td>0.570630</td>\n",
       "      <td>0.515219</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.233582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214774</td>\n",
       "      <td>0.120603</td>\n",
       "      <td>0.360674</td>\n",
       "      <td>0.345153</td>\n",
       "      <td>0.271003</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>0.632050</td>\n",
       "      <td>0.590373</td>\n",
       "      <td>0.051644</td>\n",
       "      <td>0.718582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth     fSize     fConc    fConc1     fAsym   fM3Long  \\\n",
       "0  0.074306  0.062415  0.208043  0.430390  0.293229  0.470032  0.620576   \n",
       "1  0.082815  0.045727  0.170668  0.587794  0.558601  0.468649  0.623756   \n",
       "2  0.478241  0.530579  0.626818  0.027617  0.027263  0.556215  0.468201   \n",
       "3  0.059212  0.037338  0.117445  0.683714  0.580679  0.469558  0.570630   \n",
       "4  0.214774  0.120603  0.360674  0.345153  0.271003  0.437870  0.632050   \n",
       "\n",
       "   fM3Trans    fAlpha     fDist  class  \n",
       "0  0.512493  0.445467  0.163066      0  \n",
       "1  0.507944  0.070677  0.412679      0  \n",
       "2  0.416540  0.855111  0.516926      0  \n",
       "3  0.515219  0.116100  0.233582      0  \n",
       "4  0.590373  0.051644  0.718582      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def ScaleDataframe(x_frame, ranges=(0,1)):\n",
    "    numeric = x_frame.select_dtypes(include=[np.number])\n",
    "    not_binary_cols = [col for col in numeric.columns if not set(numeric[col].dropna().unique()).issubset({0, 1})]\n",
    "    binary = numeric.drop(columns=not_binary_cols)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=ranges)\n",
    "    scaled = scaler.fit_transform(numeric[not_binary_cols])\n",
    "    scaled_df = pd.DataFrame(scaled, columns=not_binary_cols, index=x_frame.index)\n",
    "    \n",
    "    final_df = pd.concat([scaled_df, binary], axis=1)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "df_scaled = ScaleDataframe(df,(0,1))\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9ee36e-7fc9-4386-8ea2-6180281fd6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split Data\n",
    "train, temp = train_test_split(df_scaled, test_size=0.4, random_state=42)\n",
    "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "def splitdata(dataframe, Oversampling=False):\n",
    "    X = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    if Oversampling:\n",
    "        ros = RandomOverSampler()\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "    return data, X, y\n",
    "\n",
    "train, X_train, y_train = splitdata(train, True)\n",
    "valid, X_valid, y_valid = splitdata(valid)\n",
    "test, X_test, y_test = splitdata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50931d6b-b662-4383-866e-274ea5fde1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.852260778128286\n"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=10)\n",
    "pca_data = pca.fit_transform(X_train)\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=55, algorithm='auto', weights='distance', p = 1 )\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(f\"Accuracy : {knn_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0461171c-0368-40c7-bbf2-e98afca09c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7941640378548895\n"
     ]
    }
   ],
   "source": [
    "# logistic Regression\n",
    "log_model = linear_model.LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print(f\"Accuracy : {log_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6c484e-c69e-4227-841c-97ce0bcbd83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8622502628811777\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(f\"Accuracy : {svm_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc4ccdb9-d7d6-464e-84a8-d4a3103a3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.5500 - val_accuracy: 0.7158 - val_loss: 0.5335\n",
      "Epoch 2/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4049 - val_accuracy: 0.6601 - val_loss: 0.6639\n",
      "Epoch 3/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4068 - val_accuracy: 0.7980 - val_loss: 0.4232\n",
      "Epoch 4/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3680 - val_accuracy: 0.7009 - val_loss: 0.5971\n",
      "Epoch 5/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.3712 - val_accuracy: 0.7938 - val_loss: 0.4394\n",
      "Epoch 6/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3635 - val_accuracy: 0.8106 - val_loss: 0.4100\n",
      "Epoch 7/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3585 - val_accuracy: 0.7896 - val_loss: 0.4548\n",
      "Epoch 8/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3617 - val_accuracy: 0.7580 - val_loss: 0.5167\n",
      "Epoch 9/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3577 - val_accuracy: 0.8018 - val_loss: 0.4431\n",
      "Epoch 10/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3469 - val_accuracy: 0.7591 - val_loss: 0.4955\n",
      "Epoch 11/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3492 - val_accuracy: 0.7581 - val_loss: 0.4972\n",
      "Epoch 12/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3416 - val_accuracy: 0.8103 - val_loss: 0.4265\n",
      "Epoch 13/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3441 - val_accuracy: 0.8145 - val_loss: 0.4140\n",
      "Epoch 14/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3309 - val_accuracy: 0.7612 - val_loss: 0.5048\n",
      "Epoch 15/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3379 - val_accuracy: 0.8233 - val_loss: 0.3895\n",
      "Epoch 16/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3438 - val_accuracy: 0.8183 - val_loss: 0.4010\n",
      "Epoch 17/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3302 - val_accuracy: 0.7587 - val_loss: 0.5182\n",
      "Epoch 18/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3233 - val_accuracy: 0.8176 - val_loss: 0.3992\n",
      "Epoch 19/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3313 - val_accuracy: 0.8225 - val_loss: 0.3884\n",
      "Epoch 20/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3278 - val_accuracy: 0.8077 - val_loss: 0.4219\n",
      "Epoch 21/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3289 - val_accuracy: 0.7861 - val_loss: 0.4441\n",
      "Epoch 22/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3614 - val_accuracy: 0.8133 - val_loss: 0.4269\n",
      "Epoch 23/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3407 - val_accuracy: 0.8091 - val_loss: 0.4193\n",
      "Epoch 24/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3206 - val_accuracy: 0.8110 - val_loss: 0.4131\n",
      "Epoch 25/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3328 - val_accuracy: 0.8277 - val_loss: 0.3776\n",
      "Epoch 26/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3309 - val_accuracy: 0.8326 - val_loss: 0.3693\n",
      "Epoch 27/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3378 - val_accuracy: 0.8091 - val_loss: 0.4032\n",
      "Epoch 28/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3289 - val_accuracy: 0.8103 - val_loss: 0.4006\n",
      "Epoch 29/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3421 - val_accuracy: 0.7983 - val_loss: 0.4356\n",
      "Epoch 30/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3216 - val_accuracy: 0.8073 - val_loss: 0.3979\n",
      "Epoch 31/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3118 - val_accuracy: 0.8058 - val_loss: 0.4000\n",
      "Epoch 32/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3225 - val_accuracy: 0.8057 - val_loss: 0.4046\n",
      "Epoch 33/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3167 - val_accuracy: 0.7999 - val_loss: 0.4213\n",
      "Epoch 34/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3275 - val_accuracy: 0.7957 - val_loss: 0.4337\n",
      "Epoch 35/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3236 - val_accuracy: 0.7946 - val_loss: 0.4245\n",
      "Epoch 36/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3176 - val_accuracy: 0.8106 - val_loss: 0.4204\n",
      "Epoch 37/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3114 - val_accuracy: 0.7910 - val_loss: 0.4328\n",
      "Epoch 38/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3227 - val_accuracy: 0.7887 - val_loss: 0.4342\n",
      "Epoch 39/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3262 - val_accuracy: 0.7971 - val_loss: 0.4509\n",
      "Epoch 40/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.3206 - val_accuracy: 0.7795 - val_loss: 0.4898\n",
      "Epoch 41/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.3135 - val_accuracy: 0.8327 - val_loss: 0.3629\n",
      "Epoch 42/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.3263 - val_accuracy: 0.8016 - val_loss: 0.4098\n",
      "Epoch 43/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.3054 - val_accuracy: 0.7691 - val_loss: 0.4871\n",
      "Epoch 44/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3225 - val_accuracy: 0.8203 - val_loss: 0.3812\n",
      "Epoch 45/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3150 - val_accuracy: 0.7765 - val_loss: 0.4770\n",
      "Epoch 46/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3184 - val_accuracy: 0.7911 - val_loss: 0.4248\n",
      "Epoch 47/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3012 - val_accuracy: 0.8003 - val_loss: 0.4038\n",
      "Epoch 48/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3084 - val_accuracy: 0.8261 - val_loss: 0.3659\n",
      "Epoch 49/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.3054 - val_accuracy: 0.8118 - val_loss: 0.3891\n",
      "Epoch 50/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.3128 - val_accuracy: 0.7743 - val_loss: 0.4695\n",
      "Epoch 51/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3010 - val_accuracy: 0.7991 - val_loss: 0.4385\n",
      "Epoch 52/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3073 - val_accuracy: 0.7647 - val_loss: 0.4860\n",
      "Epoch 53/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.3144 - val_accuracy: 0.7939 - val_loss: 0.4627\n",
      "Epoch 54/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2990 - val_accuracy: 0.7706 - val_loss: 0.4587\n",
      "Epoch 55/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.3073 - val_accuracy: 0.8265 - val_loss: 0.3804\n",
      "Epoch 56/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3059 - val_accuracy: 0.8157 - val_loss: 0.4048\n",
      "Epoch 57/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.3156 - val_accuracy: 0.8280 - val_loss: 0.3751\n",
      "Epoch 58/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3026 - val_accuracy: 0.8371 - val_loss: 0.3604\n",
      "Epoch 59/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3064 - val_accuracy: 0.8231 - val_loss: 0.3838\n",
      "Epoch 60/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.2973 - val_accuracy: 0.7980 - val_loss: 0.4030\n",
      "Epoch 61/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3067 - val_accuracy: 0.8241 - val_loss: 0.3890\n",
      "Epoch 62/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.2978 - val_accuracy: 0.8085 - val_loss: 0.4027\n",
      "Epoch 63/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.2959 - val_accuracy: 0.7972 - val_loss: 0.4379\n",
      "Epoch 64/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3084 - val_accuracy: 0.8141 - val_loss: 0.4058\n",
      "Epoch 65/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8756 - loss: 0.2935 - val_accuracy: 0.8195 - val_loss: 0.3943\n",
      "Epoch 66/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3063 - val_accuracy: 0.8125 - val_loss: 0.3992\n",
      "Epoch 67/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.2934 - val_accuracy: 0.8226 - val_loss: 0.3893\n",
      "Epoch 68/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.3054 - val_accuracy: 0.8234 - val_loss: 0.3743\n",
      "Epoch 69/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.2981 - val_accuracy: 0.8256 - val_loss: 0.3811\n",
      "Epoch 70/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.2945 - val_accuracy: 0.7847 - val_loss: 0.4488\n",
      "Epoch 71/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.2961 - val_accuracy: 0.8144 - val_loss: 0.3875\n",
      "Epoch 72/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3184 - val_accuracy: 0.8054 - val_loss: 0.4243\n",
      "Epoch 73/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.2865 - val_accuracy: 0.8038 - val_loss: 0.4454\n",
      "Epoch 74/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.2936 - val_accuracy: 0.8041 - val_loss: 0.4116\n",
      "Epoch 75/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.2874 - val_accuracy: 0.8129 - val_loss: 0.4010\n",
      "Epoch 76/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2808 - val_accuracy: 0.8333 - val_loss: 0.3730\n",
      "Epoch 77/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.2980 - val_accuracy: 0.8141 - val_loss: 0.4027\n",
      "Epoch 78/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.2891 - val_accuracy: 0.8229 - val_loss: 0.3972\n",
      "Epoch 79/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.2933 - val_accuracy: 0.8202 - val_loss: 0.3758\n",
      "Epoch 80/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.2858 - val_accuracy: 0.8256 - val_loss: 0.3724\n",
      "Epoch 81/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.2929 - val_accuracy: 0.8035 - val_loss: 0.4152\n",
      "Epoch 82/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.2819 - val_accuracy: 0.8027 - val_loss: 0.4205\n",
      "Epoch 83/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2882 - val_accuracy: 0.8006 - val_loss: 0.3971\n",
      "Epoch 84/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2847 - val_accuracy: 0.7818 - val_loss: 0.4422\n",
      "Epoch 85/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2846 - val_accuracy: 0.8029 - val_loss: 0.4320\n",
      "Epoch 86/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.2973 - val_accuracy: 0.7853 - val_loss: 0.4453\n",
      "Epoch 87/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.2890 - val_accuracy: 0.8360 - val_loss: 0.3511\n",
      "Epoch 88/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.2904 - val_accuracy: 0.8204 - val_loss: 0.3667\n",
      "Epoch 89/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8763 - loss: 0.2940 - val_accuracy: 0.7923 - val_loss: 0.4406\n",
      "Epoch 90/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2830 - val_accuracy: 0.8137 - val_loss: 0.3989\n",
      "Epoch 91/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.2811 - val_accuracy: 0.8169 - val_loss: 0.3820\n",
      "Epoch 92/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.2886 - val_accuracy: 0.8183 - val_loss: 0.3969\n",
      "Epoch 93/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.2853 - val_accuracy: 0.8112 - val_loss: 0.3944\n",
      "Epoch 94/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2869 - val_accuracy: 0.8356 - val_loss: 0.3452\n",
      "Epoch 95/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.2968 - val_accuracy: 0.8391 - val_loss: 0.3550\n",
      "Epoch 96/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2808 - val_accuracy: 0.8214 - val_loss: 0.3835\n",
      "Epoch 97/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.2723 - val_accuracy: 0.8213 - val_loss: 0.3765\n",
      "Epoch 98/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2777 - val_accuracy: 0.8222 - val_loss: 0.3803\n",
      "Epoch 99/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2859 - val_accuracy: 0.8202 - val_loss: 0.3791\n",
      "Epoch 100/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.2848 - val_accuracy: 0.8149 - val_loss: 0.3891\n",
      "Epoch 101/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2726 - val_accuracy: 0.8229 - val_loss: 0.3704\n",
      "Epoch 102/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2698 - val_accuracy: 0.8336 - val_loss: 0.3881\n",
      "Epoch 103/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.2827 - val_accuracy: 0.8195 - val_loss: 0.3769\n",
      "Epoch 104/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2786 - val_accuracy: 0.8207 - val_loss: 0.3894\n",
      "Epoch 105/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2823 - val_accuracy: 0.7988 - val_loss: 0.4615\n",
      "Epoch 106/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.2823 - val_accuracy: 0.8079 - val_loss: 0.4202\n",
      "Epoch 107/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3001 - val_accuracy: 0.8369 - val_loss: 0.3550\n",
      "Epoch 108/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.2876 - val_accuracy: 0.8186 - val_loss: 0.4007\n",
      "Epoch 109/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.2814 - val_accuracy: 0.8071 - val_loss: 0.4036\n",
      "Epoch 110/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2738 - val_accuracy: 0.8215 - val_loss: 0.3759\n",
      "Epoch 111/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2790 - val_accuracy: 0.7988 - val_loss: 0.4217\n",
      "Epoch 112/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2733 - val_accuracy: 0.8171 - val_loss: 0.3910\n",
      "Epoch 113/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2730 - val_accuracy: 0.8150 - val_loss: 0.3796\n",
      "Epoch 114/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2645 - val_accuracy: 0.8119 - val_loss: 0.3947\n",
      "Epoch 115/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.2765 - val_accuracy: 0.7925 - val_loss: 0.4230\n",
      "Epoch 116/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2749 - val_accuracy: 0.8131 - val_loss: 0.3965\n",
      "Epoch 117/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.2725 - val_accuracy: 0.8175 - val_loss: 0.3781\n",
      "Epoch 118/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.2777 - val_accuracy: 0.8357 - val_loss: 0.3528\n",
      "Epoch 119/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2621 - val_accuracy: 0.8135 - val_loss: 0.3848\n",
      "Epoch 120/120\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2614 - val_accuracy: 0.8280 - val_loss: 0.3814\n"
     ]
    }
   ],
   "source": [
    "# NN model\n",
    "import tensorflow as tf\n",
    "\n",
    "nn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64,activation='relu',input_shape=(len(pd.array(X_train[-1,:])),)),\n",
    "    tf.keras.layers.Dense(32,activation='relu'),\n",
    "    tf.keras.layers.Dense(32,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(0.002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn_model.fit(X_train, y_train, epochs=120, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1840f5-fe7b-457b-9498-4ddba847d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8783 - loss: 0.3183\n"
     ]
    }
   ],
   "source": [
    "loss, acc = nn_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ab89c-7dfc-4d46-8e69-ac3d6c8233da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41ef8d-bb50-48e5-9874-12ffa0c4113e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
